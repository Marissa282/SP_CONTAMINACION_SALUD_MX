---
title: "Situación Problema: Contaminación ambiental y salud en México"
author: "Marissa Luna, Mariana León, Nubia Garcidueñas, Ximena Cantón."
format:
   html:
     toc: true
     html-math-method: katex
     embed-resources: true 
     self-contained-math: true
     df-print: kable
editor: source
---

Los contaminantes del aire, como el material particulado (PM₂.₅ y PM₁₀), el dióxido de azufre (SO₂), el monóxido de carbono (CO), los óxidos de nitrógeno (NOx), los compuestos orgánicos volátiles (COV) y el amoníaco (NH₃), se relacionan entre sí por su origen (industrial, vehicular) y por reacciones químicas que forman otros compuestos. Estos contaminantes impactan a los biomarcadores al provocarles cambios en su estructura o función, lo que se traduce en un indicador de exposición o daño orgánico. Los biomarcadores afectados suelen ser macromoléculas como proteínas, lípidos o carbohidratos, entre otros. 
"La exposición a la contaminación del aire está asociada con el estrés oxidativo y la inflamación de las células humanas, lo que puede sentar las bases para enfermedades crónicas y el cáncer" (NIH, s.f.).

Estos procesos impactan distintos biomarcadores biológicos, entre los que destacan:
•⁠  ⁠Marcadores hematológicos: reducción de hemoglobina
•⁠  ⁠Marcadores de inflamación: proteína C reactiva (PCR).
•⁠  ⁠Marcadores cardiovasculares y metabólicos: presión arterial, glucosa, colesterol y triglicéridos.
•⁠  ⁠Marcadores de función pulmonar.
En conjunto, la exposición a contaminantes puede alterar parámetros sanguíneos y respiratorios, aumentando el riesgo de enfermedades crónicas cardiovasculares, respiratorias y metabólicas.

# 1. Conjunto de Datos
*✏️ Una vez que cuenten con una selección de variables que les satisfaga, construyan el conjunto de datos que utilizarán. Para ello será necesario unir diferentes tablas para obtener la información necesaria.*

```{r}
#utilizamos ambiente de anaconda para cagar python
library(reticulate)
use_condaenv("base", required = TRUE)
```

```{python}
import pandas as pd 
```

```{python}
muestras= pd.read_csv("data/ensanut2022_muestras.csv", sep=";", decimal=",", encoding="utf-8-sig")
socdem= pd.read_csv("data/ensanut2022_socdem.csv", sep=";", decimal=",", encoding="utf-8-sig")
aire= pd.read_csv("data/calidad_aire_2025.csv")
```
```{python}
#Creamos diccionario para que todo los estados estén escritos igual
map_estados = {
    # Aguascalientes
    "01 AGUASCALIENTES": "Aguascalientes",
    "Aguascalientes": "Aguascalientes",

    # Baja California
    "02 BAJA CALIFORNIA": "Baja california",
    "Baja California": "Baja california",

    # Baja California Sur
    "03 BAJA CALIFORNIA SUR": "Baja california sur",
    "Baja California Sur": "Baja california sur",

    # Campeche
    "04 CAMPECHE": "Campeche",
    "Campeche": "Campeche",

    # Coahuila
    "05 COAHUILA DE ZARAGOZA": "Coahuila",
    "Coahuila": "Coahuila",

    # Colima
    "06 COLIMA": "Colima",
    "Colima": "Colima",

    # Chiapas
    "07 CHIAPAS": "Chiapas",
    "Chiapas": "Chiapas",

    # Chihuahua
    "08 CHIHUAHUA": "Chihuahua",
    "Chihuahua": "Chihuahua",

    # Ciudad de México
    "09 CIUDAD DE MÉXICO": "Ciudad de mexico",
    "Ciudad de México": "Ciudad de mexico",

    # Durango
    "10 DURANGO": "Durango",
    "Durango": "Durango",

    # Guanajuato
    "11 GUANAJUATO": "Guanajuato",
    "Guanajuato": "Guanajuato",

    # Guerrero
    "12 GUERRERO": "Guerrero",
    "Guerrero": "Guerrero",

    # Hidalgo
    "13 HIDALGO": "Hidalgo",
    "Hidalgo": "Hidalgo",

    # Jalisco
    "14 JALISCO": "Jalisco",
    "Jalisco": "Jalisco",

    # Estado de México
    "15 MÉXICO": "Estado de mexico",
    "Estado de México": "Estado de mexico",

    # Michoacán
    "16 MICHOACÁN DE OCAMPO": "Michoacan",
    "Michoacán": "Michoacan",

    # Morelos
    "17 MORELOS": "Morelos",
    "Morelos": "Morelos",

    # Nayarit
    "18 NAYARIT": "Nayarit",
    "Nayarit": "Nayarit",

    # Nuevo León
    "19 NUEVO LEÓN": "Nuevo leon",
    "Nuevo León": "Nuevo leon",

    # Oaxaca
    "20 OAXACA": "Oaxaca",
    "Oaxaca": "Oaxaca",

    # Puebla
    "21 PUEBLA": "Puebla",
    "Puebla": "Puebla",

    # Querétaro
    "22 QUERÉTARO": "Queretaro",
    "Querétaro": "Queretaro",

    # Quintana Roo
    "23 QUINTANA ROO": "Quintana roo",
    "Quintana Roo": "Quintana roo",

    # San Luis Potosí
    "24 SAN LUIS POTOSÍ": "San luis potosi",
    "San Luis Potosí": "San luis potosi",

    # Sinaloa
    "25 SINALOA": "Sinaloa",
    "Sinaloa": "Sinaloa",

    # Sonora
    "26 SONORA": "Sonora",
    "Sonora": "Sonora",

    # Tabasco
    "27 TABASCO": "Tabasco",
    "Tabasco": "Tabasco",

    # Tamaulipas
    "28 TAMAULIPAS": "Tamaulipas",
    "Tamaulipas": "Tamaulipas",

    # Tlaxcala
    "29 TLAXCALA": "Tlaxcala",
    "Tlaxcala": "Tlaxcala",

    # Veracruz
    "30 VERACRUZ DE IGNACIO DE LA LLAVE": "Veracruz",
    "Veracruz": "Veracruz",

    # Yucatán
    "31 YUCATÁN": "Yucatan",
    "Yucatán": "Yucatan",

    # Zacatecas
    "32 ZACATECAS": "Zacatecas",
    "Zacatecas": "Zacatecas"
}
```


```{python}
#mapeamos el diccionario a los nombre de estados a cambiar
import re
socdem["Entidad"] = socdem["desc_ent1"].map(map_estados)
aire["Entidad"]= aire["Entidad"].map(map_estados)
muestras["Entidad"] = muestras["desc_ent"].map(map_estados)
```

```{python}
#agrupamos por Entidad para facilitar el merge 
aire= aire.groupby("Entidad")[["SO_2", "CO","NOx", "COV", "PM_010", "PM_2_5", "NH_3" ]].sum().reset_index()
```

```{python}
#merge entre aire y socdem
df_joined = pd.merge(socdem, aire, on = "Entidad", how = "inner")
df_joined
```

```{python}
#merge entre df_final y muestras
df_final = pd.merge(df_joined, muestras, on = "FOLIO_INT", how = "left")
df_final
```

```{python}
#elegimos las columnas finales
columnas= ["NH_3", "valor_INSULINA", "valor_CREAT", "CO", "valor_HB1AC"
           , "h0303_x", "h0302_x", "estrato_x", "SO_2", "NOx", "valor_VIT_D", "valor_STFR_FEB23", "valor_PCR", "valor_ALBU"]
df_finalisimo= df_final[columnas]
```

```{python}
#vemos si hay Nan
df_finalisimo.isna().sum()
#vemos si hay espacios vacíos 

#revismaos que vengan desde los df originales
muestras["valor_HB1AC"].str.contains(r'^\s*$', na=False).sum() #hay un monton de espacios 
```

```{python}
#dropeamos vacíos y Nan
import numpy as np
df_finalisimo = df_finalisimo.replace(r'^\s*$', np.nan, regex=True)
df_finalisimo = df_finalisimo.dropna().reset_index(drop=True)
```

```{python}
#renombramos las columnas
df_finalisimo
df_finalisimo.columns = ["Am", "I", "C", "M", "H", "E", "S", "U", "D", "O", "VD", "T", "PCR", "AL"]
```

```{python}
#rempalzamos comas. por puntos y los hacemos float
df_finalisimo = df_finalisimo.apply(lambda col:
    col.astype(str).str.replace(",", ".", regex=False).astype(float)
)
```

```{python}
#cambiamos a int U y S
df_finalisimo['U'] = df_finalisimo['U'].astype(int)
df_finalisimo['S'] =df_finalisimo['S'].astype(int)
```

```{python}
df_finalisimo.head()
```

```{python}
df_finalisimo.info()
df_finalisimo.to_csv("data/datos_contaminacion.csv", index=False)
```


## 2. Ajuste de red Gaussiana y Scores. 
*✏️ Ajusten una GBN para cada una de las DAG propuestas. ✏️ Reporten el BIC y el AIC para cada GBN*

```{r}
library(tidyverse)
library(bnlearn)
```

```{r}
data = read_csv("/Users/marissaluna/Documents/SP_CONTAMINACION/data/datos_contaminacion.csv")
head(data)
```

```{r}
data = data |>
        select(c(-U,-S)) # Dropeamos S y U
```

Creamos la DAG 1:

```{r}
dag1= model2network("[Am][M][D][O][E][PCR|Am:M:D:O:E:VD][VD|E][AL|E:PCR][T|E:PCR][I|E:PCR:VD:AL][C|E:Am:D:O][H|E:M:PCR:T]")
```

Visualizamos la DAG 1:

```{r}
graphviz.plot(dag1, shape = "ellipse")
```

Ahora, realizamos el ajuste para la DAG 1:

```{r}
dag1_fit = bn.fit(dag1, data=data)
```

Sacamos el BIC de la DAG 1:

```{r}
score(dag1, data= data, type = "bic-g")
```

Sacamos el AIC de la DAG 1:

```{r}
score(dag1, data= data, type = "aic-g")
```

Creamos la DAG 2:

```{r}
dag2 = model2network("[M][E][O|M][D|M][Am|M][AL|E][PCR|AL:E][T|PCR][VD|PCR:E][C|E][H|E][I|E:O]")# Le metemos la esctrutura de la DAG
```

Visualizamos la DAG 2:

```{r}
graphviz.plot(dag2, shape = "ellipse")
```

Ahora, realizamos el ajuste para la DAG 2:

```{r}
dag2_fit = bn.fit(dag2, data=data)
```

Sacamos el BIC de la DAG 2:

```{r}
score(dag2, data= data, type = "bic-g")
```

Sacamos el AIC de la DAG 2:

```{r}
score(dag2, data= data, type = "aic-g")
```

Creamos la DAG 3:

```{r}
dag3 = empty.graph(nodes = c( "Am", "I", "C", "M", "H", "E", "O", "D", "VD", "T", "PCR", "AL"))
arc_set = matrix(c(
                   "Am", "C",
                   "Am", "PCR", 
                   "Am", "VD", 
                   "M", "C",
                   "M", "PCR", 
                   "M", "VD", 
                   "D", "C",
                   "D", "PCR", 
                   "D", "VD",
                   "O", "C",
                   "O", "PCR", 
                   "O", "VD",
                   "VD", "I",
                   "I", "H", 
                   "E", "C", 
                   "E", "H", 
                   "PCR", "AL", 
                   "PCR", "T", 
                   "T", "H"
                   ), byrow = TRUE, ncol = 2,
                 dimnames = list(NULL, c("from", "to")))
```

```{r}
arcs(dag3) = arc_set
```

Visualizamos la DAG 3:

```{r}
graphviz.plot(dag3, shape = "ellipse")
```

Ahora, realizamos el ajuste para la DAG 3:

```{r}
dag3_fit = bn.fit(dag3, data=data)
```

Sacamos el BIC de la DAG 3:

```{r}
score(dag3, data= data, type = "bic-g")
```

Sacamos el AIC de la DAG 3:

```{r}
score(dag3, data= data, type = "aic-g")
```
## 3. Inclusión de variables categóricas
*✏️ Investiguen y discutan cómo podrían incluir las variables categóricas a la red, por ejemplo, una variable de interés puede ser el sexo. Se pueden incluir como nuevos nodos padre en la mejor DAG, de modo que no afecte las relaciones en la DAG ya establecida como la mejor.*

Si ya se tiene una GBN (red bayesiana gaussiana) y se busca añadir un par de variables categóricas, lo ideal para incluirlas, es seguir las siguientes "reglas":

- ⁠Nodos discretos (variables categóricas) no pueden tener padres continuos.
- ⁠Nodos continuos (biomarcadores, contaminantes) sí pueden tener padres discretos y continuo. 

Por tanto, se orientan los arcos de lo discreto → a lo continuo. 

- ⁠No cambiar la DAG existente; sólo agregar pocos arcos salientes desde cada variable categórica a los biomarcadores/variables continuas.

## 4. Usando sexo (S) y urbanidad (U)
*✏️ Con la mejor estructura que han encontrado hasta el momento, intenten incluir el sexo de las personas.*

Ahora, siendo la dag2 la mejor dag, incluimos las variables categóricas de "S = sexo" y "U = urbanidad/estrato":

```{r}
best_dag = model2network("[U][M][E][S][O|U][D|U:M][Am|M][AL|U:E][PCR|AL:E:S][T|PCR][VD|S:PCR:E][C|E:S][H|S:E][I|S:E]")
```

```{r}
graphviz.plot(best_dag, shape = "ellipse")
```

## 5. Querys
*✏️ Con ayuda de las personas especialistas propongan al menos 3 queries que podrían resolver utilizando su red bayesiana y respóndalas usando su mejor modelo.*

1.  ¿Qué probabilidad hay de que una persona de 45 años, tenga la insulina alta si fijamos los contaminantes en valores específicos? Supuesto: NOx=60, SO₂=40, CO=6, NH₃=10 y Edad=45.

```{r}
# I: Insulina, O: NOx, D: SO₂, M: CO, Am: NH₃, E: Edad
cpquery(dag2_fit,event    = (I > 12),evidence = list(O = 60, D = 40, M = 6, Am = 10, E = 45), method   = "lw")
```

2.  ¿Qué probabilidad hay de que la creatinina salga alta durante episodios de alta contaminación? Escenario: (NOx \> 50) o (CO ≥ 6 y SO₂ ≥ 40).

```{r}
# C: Creatinina
cpquery(dag2_fit, event    = (C >= 1.3), evidence = ((O > 50) | (M >= 6 & D >= 40)),n = 10^6)
```

3.  ¿Qué probabilidad hay de que la hemoglobina esté en rango de diabetes (≥ 6.5%) cuando una persona adulta ya tiene insulina alta y está expuesta a contaminantes? Escenario: Adultos (E ≥ 40) con hiperinsulinemia (I ≥ 12) y exposición alta a NOx o SO₂.

```{r}
# H: HbA1c, I: Insulina, O: NOx, D: SO₂, E: Edad
cpquery(dag2_fit,event    = (H >= 6.5),evidence = (E >= 40 & I >= 12 & (O >= 50 | D >= 40)),n = 10^6)
```
